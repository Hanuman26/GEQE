import os

"""
All settings required to operate the GeqeConsumer and GeqeRunner
to execute jobs on behalf of the geqe-webserver
"""

# set to None to lauch spark jobs, otherwise mock data is returned instead.
# MOCK_DATA_PATH = None
MOCK_DATA_PATH = {
    "location": "GeqeUtil/MOCK_JOB_DATA/locationResult.json",
    "event" : "GeqeUtil/MOCK_JOB_DATA/eventResult.json"
}

LOOPBACK_SERVICE = "http://localhost:5500"
WAIT_TIME = 5   #polling interval (Seconds)
SPARK_SUBMIT_PATH = "spark-submit"
PROJECT_ROOT_PATH = ""   # replace with full file system path to this project


#automatically include all project python files when running spark submit
PY_FILES = []
def getFiles(subdir):
  return map(lambda x: subdir+'/'+x,filter(lambda x: x[-3:] == '.py', os.listdir(PROJECT_ROOT_PATH+'/'+subdir)))
for subdir in ['geqe-comm','geqe-ml','geqe-ml/lib']:
  PY_FILES.extend(getFiles(subdir))


SPARK_OPTIONS = [
    "--master" , "local",
    "--py-files" , ','.join(PY_FILES),
    "--executor-memory" , "4g",
    "--driver-memory" ,  "2g",
    "--total-executor-cores", "4"
]

# specify an elastic search host to add result-set data to elastic search in addition to the geqe-dataserver
ES_HOST = None
ES_PORT = 9200
